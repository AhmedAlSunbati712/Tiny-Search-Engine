# Querier – Assumptions, Deviations & Implementation

## Assumptions

- **Valid Index File**: We assume the provided index file is well-formed and produced by the indexer, with words and counts formatted correctly.
- **Page Directory**: We assume the `pageDirectory` was generated by the crawler and contains valid files with readable first lines (URLs).
- **Input Format**: Query strings are assumed to contain only lowercase alphabetic characters and valid Boolean operators (`AND`, `OR`). Extra whitespace is trimmed and ignored. If input has any uppercase alphabetic characters, they are converted to lowercase.
- **Document ID Validity**: We assume all document IDs referenced in the index are present in the page directory and correspond to valid files.

## Functionality implemented
- Querier supports 'and' and 'or' boolean operators.
- 'and' has higher precedence than 'or' (correct operator precedence).
- Results are printed in decreasing order of score.

## Implementatino Specs
We will cover the following topics:
- Data Structures
- Control Flow
- Detailed function prototypes and their parameters
- Error handling and recovery
- Testing plan

## Data Structures
Two major data structures: `document` and `query`. `document` is a data structure used to store a document ID and its score. `query` is an alias of bag, and its a collection of `documents`.
## Control Flow
The querier is implemented in one file `querier.c`, with 5 functions:
### main
The `main` function calls `parseArgs`, validates CLI, and prompts the user with a query. It then normalizes this query with `normalizeInput` function found in the `word` module. After normalizing the input, it checks if its syntax is valid using `isInputValid`. If the syntax is valid, `main` enters a loop that exits only when the program reached `EOF`. It then calls `querierProcess` on the query to find matching documents, and prints out the found documents using `printDoucments`.
### parseArgs
Given three arguments from the command line, it extracts them into the function parameters; return only if successful.
- Checks if the number of arguments `argc == 3`.
- Parses the second argument into `pageDirectory`.
- Parses the third argument into `indexFileName`.
### isInputValid
Validates the syntax of a query. Makes sure that there isn't a consecutive sequence of operators, the query doesn't end/start with an operator, and the query isn't empty.
```
if line is NULL or empty:
    return false
extract first word from line
if first word is "and" or "or":
    return false
isLastWordOperator ← false
for each word in line:
    if word is "and" or "or":
        if isLastWordOperator:
            return false
        isLastWordOperator ← true
    else:
        isLastWordOperator ← false
if isLastWordOperator:
    return false
return true
```
### querierProcess
Searches up documents that matches the normalized query using the index and the crawler pageDir:
```
listOfWords ← split normalizedQuery into words
queryFinalResults ← new empty query
currQueryResult ← new empty query
for each word in listOfWords:
    if word is "or":
        queryFinalResults ← union of queryFinalResults and currQueryResult
        reset currQueryResult to new empty query
    else if word is not an operator:
        tempQuery ← documents matching word from index
        currQueryResult ← intersection of currQueryResult and tempQuery

queryFinalResults ← union of queryFinalResults and currQueryResult
return queryFinalResults
```
### printDocuments
Prints the sorted list of documents from a query result to the provided file stream. Each document's score, ID, and URL are printed. Also handles cleanup of allocated memory.
```
sortedDocs ← get documents from queryResults, sorted by score
for each document in sortedDocs:
    print document info (score, ID, URL) to outputStream using pageDir
free sortedDocs
```

## Other Modules
### query
We create a reusable module `query.c` to handle storing documents that match a certain query and their scores. It aliases the bag data structure to a data structure called `bag_t`, with items being of the `document_t` data structure. It includes various useful functions, but the ones that are really vital for the functionality of `querier` are `query_intersect` and `query_union`:
#### query_union
Returns a new query result set containing all unique documents from both inputs:
```
function query_union(qresults1, qresults2):
    if both qresults1 and qresults2 exist:
        create empty hashtable seenDocs
        for each doc in qresults1:
            add or accumulate doc score in seenDocs
        for each doc in qresults2:
            add or accumulate doc score in seenDocs
        create new query result queryUnion
        for each entry in seenDocs:
            add document to queryUnion
        delete seenDocs
        return queryUnion

    else if only qresults1 exists:
        return deep copy of qresults1

    else if only qresults2 exists:
        return deep copy of qresults2

    else:
        return NULL
```
#### query_intersect
Returns a new query result set containing only documents present in both inputs. Caller is responsible for freeing qresults1 & qresults2 later. The function also makes use of an internally defined struct called `seenDocsIntersect` that contain a `seenDocs` and `commonDocs` hashtable. The seenDocs is passed over the first qresults1. Then we iterate through the second qresults with this struct, and if any document exists in seenDocs, we add it to commonDocs. Finally we build the intersection using documents from commonDocs.
```
function query_intersect(qresults1, qresults2):
    if both qresults1 and qresults2 are non-empty:
        create empty hashtable seenDocs
        create empty hashtable commonDocs
        create seenDocsIntersect struct with seenDocs and commonDocs

        for each doc in qresults1:
            add doc to seenDocs

        for each doc in qresults2:
            if doc exists in seenDocs:
                add to commonDocs with minimum score

        create new query result queryIntersect
        for each entry in commonDocs:
            add document to queryIntersect

        delete seenDocs, commonDocs, and helper struct
        return queryIntersect

    else if only one of qresults1 or qresults2 is non-empty:
        return deep copy of the non-empty result

    else:
        return NULL
```
# Function Prototypes
## querier
Detailed descriptions of each function is given in `querier.c`:
```c
void parseArgs(const int argc, const char* argv[], char** pageDirectory, char** indexFilename);
query_t* querierProcess(char* normalizedQuery, index_t* index, char* pageDir);
bool isInputValid(char* line);
void printDocuments(FILE* fp, query_t* qresults, char* pageDir);
static int compareDocs(const void* a, const void* b);
static document_t** extractDocumentsSorted(query_t* qresults);
static void queryExtractHelper(document_t** docsArray, query_t* qresults);
static void printDocumentsHelper(FILE* fp, document_t* doc, char* pageDir);
```
## query
Detailed descriptions of each function is given in `query.c`
```c
query_t* query_new(void);
void query_add_document(query_t* qresults, document_t* doc);
void query_iterate(query_t* qresults, void* arg, void (*itemfunc)(void* arg, void* doc));
int query_size(query_t* qresults);
document_t* query_extract(query_t* qresults);
void query_search_index(query_t* qresults, index_t* index, char* word);
query_t* query_intersect(query_t* qresults1, query_t* qresults2);
query_t* query_union(query_t* qresults1, query_t* qresults2);
void query_delete(query_t* qresults);
```
With internally defined functions that act as helpers:
```c
static void query_search_helper(void* arg, const int docID, const int count);
static void seen_docs_to_query_helper(void* queriesUnion, const char* docID, void* docScore);
static void query_seen_docs_union_helper(void* seenDocs, void* doc);
static void query_seen_docs(void* seenDocs, void* doc);
static void document_delete_helper(void* item);
static void query_size_helper(void* size, void* doc);
static void query_iterate_copy_item(void* qresults, void* doc);
static seenDocsIntersect_t* query_seenDocs_struct_new(hashtable_t* seenDocs, hashtable_t* commonDocs);
static void query_intersect_helper(void* seenDocsIntersect, void* doc);
```
## word
Detailed descriptions of each function is given in `word.c`:
```c
char* normalizeWord(const char* word);
char* normalizeInput(char* line);
char** deconstructLine(char* line);
void freeDeconstructedLine(char** listOfWords);
```
# Error-handling & Recovery
Out-of-memory errors are handled by variants of the mem_assert functions, which result in a message printed to stderr and a non-zero exit status. We anticipate out-of-memory errors to be rare and thus allow the program to crash (cleanly) in this way.

All code uses defensive-programming tactics to catch and exit (using variants of the mem_assert functions), e.g., if a function receives bad parameters.

Errors that can arise from saving an index file are also checked. If an error is encountered while trying to save an index, the program exits with code 1 and prints and error message to `stderr`.
## Testing plan
_Integration Testing_ The querier as a complete program will be tested using the following methods:
- Invalid crawler directory
- Invalid index pathname
- Invalid queries (consecutive operators, operators at the start, operators at the end..etc).
- Empty query.
- Non-matching queries.